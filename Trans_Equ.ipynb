{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "from plotting import newfig, savefig\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-informed Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the deep neural network\n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        self.depth = len(layers) - 1\n",
    "        \n",
    "        # set up layer order dict\n",
    "        self.activation = torch.nn.Tanh\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(self.depth - 1): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "        \n",
    "        # deploy layers\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the physics-guided neural network\n",
    "class PhysicsInformedNN():\n",
    "    def __init__(self, X, u, layers, lb, ub):\n",
    "        \n",
    "        # boundary conditions\n",
    "        self.lb = torch.tensor(lb).float().to(device)\n",
    "        self.ub = torch.tensor(ub).float().to(device)\n",
    "        \n",
    "        # data\n",
    "        self.x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        self.t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "        self.u = torch.tensor(u).float().to(device)\n",
    "        \n",
    "        # settings\n",
    "        self.lambda_1 = torch.tensor([1.0], requires_grad=True).to(device)\n",
    "        self.lambda_2 = torch.tensor([-5.0], requires_grad=True).to(device)\n",
    "        \n",
    "        self.lambda_1 = torch.nn.Parameter(self.lambda_1)\n",
    "        self.lambda_2 = torch.nn.Parameter(self.lambda_2)\n",
    "        \n",
    "        # deep neural networks\n",
    "        self.dnn = DNN(layers).to(device)\n",
    "        self.dnn.register_parameter('lambda_1', self.lambda_1)\n",
    "        self.dnn.register_parameter('lambda_2', self.lambda_2)\n",
    "        \n",
    "         # optimizers: using the same settings\n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.dnn.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n",
    "        )\n",
    "        \n",
    "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
    "        self.iter = 0\n",
    "        \n",
    "    def net_u(self, x, t):  \n",
    "        u = self.dnn(torch.cat([x, t], dim=1))\n",
    "        return u\n",
    "    \n",
    "    def net_f(self, x, t):\n",
    "        \"\"\" The pytorch autograd version of calculating residual \"\"\"\n",
    "        lambda_1 = self.lambda_1        \n",
    "        lambda_2 = torch.exp(self.lambda_2)\n",
    "        u = self.net_u(x, t)\n",
    "        \n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        f = u_t + lambda_1 * u_x - lambda_2 * u_xx\n",
    "        return f\n",
    "    \n",
    "    def loss_func(self):\n",
    "        u_pred = self.net_u(self.x, self.t)\n",
    "        f_pred = self.net_f(self.x, self.t)\n",
    "        loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        self.iter += 1\n",
    "        if self.iter % 100 == 0:\n",
    "            print(\n",
    "                'Loss: %e, l1: %.5f, l2: %.5f' % \n",
    "                (\n",
    "                    loss.item(), \n",
    "                    self.lambda_1.item(), \n",
    "                    torch.exp(self.lambda_2.detach()).item()\n",
    "                )\n",
    "            )\n",
    "        return loss\n",
    "    \n",
    "    def train(self, nIter):\n",
    "        self.dnn.train()\n",
    "        for epoch in range(nIter):\n",
    "            u_pred = self.net_u(self.x, self.t)\n",
    "            f_pred = self.net_f(self.x, self.t)\n",
    "            loss = torch.mean((self.u - u_pred) ** 2) + torch.mean(f_pred ** 2)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            self.optimizer_Adam.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_Adam.step()\n",
    "            \n",
    "            if epoch % 100 == 0:\n",
    "                print(\n",
    "                    'It: %d, Loss: %.3e, Lambda_1: %.3f, Lambda_2: %.6f' % \n",
    "                    (\n",
    "                        epoch, \n",
    "                        loss.item(), \n",
    "                        self.lambda_1.item(), \n",
    "                        torch.exp(self.lambda_2).item()\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "        # Backward and optimize\n",
    "        self.optimizer.step(self.loss_func)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
    "        t = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
    "\n",
    "        self.dnn.eval()\n",
    "        u = self.net_u(x, t)\n",
    "        f = self.net_f(x, t)\n",
    "        u = u.detach().cpu().numpy()\n",
    "        f = f.detach().cpu().numpy()\n",
    "        return u, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.01/np.pi\n",
    "\n",
    "N_u = 2000\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "\n",
    "data = scipy.io.loadmat('data.mat')\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.691951e-03, l1: 1.00707, l2: 0.00013\n",
      "Loss: 1.475483e-04, l1: 0.99993, l2: 0.00000\n",
      "Loss: 4.085082e-05, l1: 1.00388, l2: 0.00000\n",
      "Loss: 2.557024e-05, l1: 1.00594, l2: 0.00000\n",
      "CPU times: user 15.3 s, sys: 76 ms, total: 15.4 s\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "noise = 0.0            \n",
    "\n",
    "# create training set\n",
    "idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
    "X_u_train = X_star[idx,:]\n",
    "u_train = u_star[idx,:]\n",
    "\n",
    "# training\n",
    "model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
    "model.train(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error u: 7.474726e-02\n",
      "Error l1: 2.28842%\n",
      "Error l2: 99.86533%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u_pred, f_pred = model.predict(X_star)\n",
    "\n",
    "error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "\n",
    "U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
    "\n",
    "lambda_1_value = model.lambda_1.detach().cpu().numpy()\n",
    "lambda_2_value = model.lambda_2.detach().cpu().numpy()\n",
    "lambda_2_value = np.exp(lambda_2_value)\n",
    "\n",
    "error_lambda_1 = np.abs(lambda_1_value - 1.0) * 100\n",
    "error_lambda_2 = np.abs(lambda_2_value - nu) / nu * 100\n",
    "\n",
    "print('Error u: %e' % (error_u))    \n",
    "print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
    "print('Error l2: %.5f%%' % (error_lambda_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### Row 1: u(t,x) slices ################## \n",
    "\n",
    "\"\"\" The aesthetic setting has changed. \"\"\"\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "gs1 = gridspec.GridSpec(1, 3)\n",
    "gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 0])\n",
    "ax.plot(x,Exact[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')    \n",
    "ax.set_title('$t = 0.25$', fontsize = 15)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-5,5])\n",
    "ax.set_ylim([0,3])\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1])\n",
    "ax.plot(x,Exact[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-5,5])\n",
    "ax.set_ylim([0,3])\n",
    "ax.set_title('$t = 0.50$', fontsize = 15)\n",
    "ax.legend(\n",
    "    loc='upper center', \n",
    "    bbox_to_anchor=(0.5, -0.15), \n",
    "    ncol=5, \n",
    "    frameon=False, \n",
    "    prop={'size': 15}\n",
    ")\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2])\n",
    "ax.plot(x,Exact[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-5,5])\n",
    "ax.set_ylim([0,3])    \n",
    "ax.set_title('$t = 0.75$', fontsize = 15)\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
